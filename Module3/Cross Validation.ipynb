{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b8f26d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Optional: install scikit-learn if not already available in your environment\n",
    "#!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e973465",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Dependency installation hints (only needed if your local env is missing packages)\n",
    "# All libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n",
    "#!mamba install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n",
    "# Note: If your environment doesn't support \"!mamba install\", use \n",
    "# \"!pip install pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5df9cd4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Suppress warnings to keep the notebook output clean\n",
    "# (Use cautiously in real projects; warnings can be useful.)\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598a27cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# In-browser (Pyodide) environment: install packages at runtime\n",
    "# If running locally, you can skip this cell.\n",
    "import piplite\n",
    "await piplite.install(['tqdm', 'seaborn', 'pandas', 'numpy', 'scikit-learn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a89828",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Core scientific stack and visualization\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Scikit-learn: model building, evaluation, and utilities\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927d6c3b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Download dataset in Pyodide; comment this out if running locally with a local file\n",
    "from pyodide.http import pyfetch\n",
    " \n",
    "async def download(url, filename):\n",
    "    response = await pyfetch(url)\n",
    "    if response.status == 200:\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(await response.bytes())\n",
    " \n",
    "path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML240EN-SkillsNetwork/labs/encoded_car_data.csv\"\n",
    " \n",
    "# You will need to download the dataset; if running locally with the file present, skip the next line\n",
    "await download(path, \"encoded_car_data.csv\")\n",
    " \n",
    " \n",
    "# Load the dataset into a pandas DataFrame\n",
    "# Import pandas library\n",
    "import pandas as pd\n",
    " \n",
    "# Read the downloaded CSV and inspect the head\n",
    "# Read the online file by the URL provides above, and assign it to variable \"df\"\n",
    "data = pd.read_csv(\"encoded_car_data.csv\")\n",
    " \n",
    "# Show the first 5 rows for a quick sanity check\n",
    "# show the first 5 rows using dataframe.head() method\n",
    "print(\"The first 5 rows of the dataframe\") \n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2114675",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Quick schema/summary of the dataset: dtypes, non-nulls, memory\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8769c4f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec9f4f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Hold-out split for initial evaluation (30% test, fixed random_state for reproducibility)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa86d116",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize a baseline Linear Regression model\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd2e786",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model on the training set\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ea9edd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Generate predictions on the test set\n",
    "predicted =lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5495251",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# R^2 on training data (fit quality). Beware of overfitting if this is much higher than test.\n",
    "lr.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa2988",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# R^2 on test data (generalization performance)\n",
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Explicit R^2 computation should match lr.score on the test set\n",
    "print(r2_score(y_true=y_test, y_pred=predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc22046d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# RMSE: square root of MSE, interpretable in target units\n",
    "mse = mean_squared_error(y_true=y_test, y_pred=predicted)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fc5cea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Take a few samples to compare predictions vs labels\n",
    "some_data = X.iloc[:3]\n",
    "some_labels = y.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917b3309",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Show predicted values for the small sample\n",
    "print(\"Predictions:\", lr.predict(some_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Show ground-truth labels for the same sample\n",
    "print(\"Labels:\", list(some_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c6ceb5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Recompute and display predictions for full test set (for inspection)\n",
    "predicted =lr.predict(X_test)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b472dd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Pipeline example: scale features then fit Linear Regression\n",
    "pipe = Pipeline([('ss',StandardScaler() ),('lr', LinearRegression())])\n",
    "pipe.fit(X_train,y_train)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f747de",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# (Intentionally left empty in original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2060fe03",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Pipeline R^2 on training data\n",
    "pipe.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f09d2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Pipeline R^2 on test data\n",
    "pipe.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e151e369",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Alternative pipeline: use Normalizer (L2 vector normalization) before Linear Regression\n",
    "pipe_1 = Pipeline([('nn',Normalizer() ),('lr', LinearRegression())])\n",
    "pipe_1.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate pipeline_1\n",
    "pipe_1.score(X_train,y_train)\n",
    "pipe_1.score(X_test,y_test)\n",
    "\n",
    "# Predict and compute RMSE\n",
    "pred =pipe_1.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_true=y_test, y_pred=pred)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd34a04",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# List feature names for simple univariate analysis\n",
    "features=list(X)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00675df",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Univariate feature assessment: train and evaluate using one feature at a time (train R^2)\n",
    "R_2=[]\n",
    "pipe = Pipeline([('ss',StandardScaler() ),('lr', LinearRegression())])\n",
    "\n",
    "for feature in features:\n",
    "    pipe.fit(X_train[[feature]],y_train)\n",
    "    R_2.append(pipe.score(X_train[[feature]],y_train))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0d0b9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize training R^2 by single-feature models\n",
    "plt.bar(features,R_2)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"$R^2$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the best single feature by training R^2\n",
    "best=features[np.argmax(R_2)]\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Fit on the full dataset using only the best single feature (for illustration)\n",
    "pipe.fit(X[[best]],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Univariate test performance: fit on train, evaluate on test using one feature at a time\n",
    "R_2=[]\n",
    "\n",
    "for feature in features:\n",
    "      lr.fit(X_train[[feature]], y_train)\n",
    "      R_2.append(lr.score(X_test[[feature]],y_test))\n",
    "\n",
    "best=features[np.argmax(R_2)]\n",
    "\n",
    "# Visualize test R^2 across single-feature models\n",
    "plt.bar(features,R_2)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"$R^2$\")\n",
    "plt.show()\n",
    "\n",
    "# Print the best feature on the test set\n",
    "best=features[np.argmax(R_2)]\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09946e35",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Number of samples\n",
    "N=len(X)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Fresh Linear Regression instance for cross-validation\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9178e158",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cross-validation with 3 folds using R^2 as the metric\n",
    "scores = cross_val_score(lr, X, y, scoring =\"r2\", cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b488b6ce",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# View fold-wise R^2 scores\n",
    "scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7c9127",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Helper to summarize CV scores\n",
    "def display_scores(scores, print_=False):\n",
    "    \n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae27cd39",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Summarize R^2 CV results\n",
    "display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e3da9c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cross-validation with 5 folds using RMSE (via neg_mean_squared_error)\n",
    "scores = cross_val_score(lr, X ,y, scoring =\"neg_mean_squared_error\", cv=5)\n",
    "lr_scores = np.sqrt(-scores)\n",
    "display_scores(lr_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2912e25e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Manual KFold setup\n",
    "n_splits=2\n",
    "kf = KFold(n_splits = n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e309e028",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate through KFold splits, fit pipeline, and store R^2 on each test fold\n",
    "y = data['price'].copy()\n",
    "X = data.drop(columns=['price'])\n",
    "R_2 = np.zeros((n_splits,1))\n",
    "pipe = Pipeline([('ss',StandardScaler() ),('lr', LinearRegression())])\n",
    "n=0\n",
    "for k,(train_index, test_index) in enumerate(kf.split(X,y)):\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)\n",
    "    X_train, X_test =X.iloc[train_index],X.iloc[test_index]\n",
    "    \n",
    "    y_train, y_test=y[train_index],y[test_index]\n",
    "    pipe.fit(X_train,y_train)\n",
    "    n=+1\n",
    "    R_2[k]=pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a33225",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Average R^2 across folds\n",
    "R_2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954140cd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Repeat KFold with 3 splits and compute mean test R^2\n",
    "n_splits=3\n",
    "kf = KFold(n_splits = n_splits)\n",
    "y = data['price'].copy()\n",
    "X = data.drop(columns=['price'])\n",
    "R_2=np.zeros((n_splits,1))\n",
    "pipe = Pipeline([('ss',StandardScaler() ),('lr', LinearRegression())])\n",
    "n=0\n",
    "for k,(train_index, test_index) in enumerate(kf.split(X,y)):\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)\n",
    "    X_train, X_test =X.iloc[train_index],X.iloc[test_index]\n",
    "    \n",
    "    y_train, y_test=y[train_index],y[test_index]\n",
    "    pipe.fit(X_train,y_train)\n",
    "    n=+1\n",
    "    R_2[k]=pipe.score(X_test, y_test)\n",
    "    \n",
    "    \n",
    "R_2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe11e1c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# KFold with shuffling; otherwise same evaluation\n",
    "n_splits=3\n",
    "kf = KFold(n_splits = n_splits,shuffle=True)\n",
    "y = data['price'].copy()\n",
    "X = data.drop(columns=['price'])\n",
    "R_2=np.zeros((n_splits,1))\n",
    "pipe = Pipeline([('ss',StandardScaler() ),('lr', LinearRegression())])\n",
    "n=0\n",
    "for k,(train_index, test_index) in enumerate(kf.split(X,y)):\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)\n",
    "    X_train, X_test =X.iloc[train_index],X.iloc[test_index]\n",
    "\n",
    "    y_train, y_test=y[train_index],y[test_index]\n",
    "    pipe.fit(X_train,y_train)\n",
    "    n=+1\n",
    "    R_2[k]=pipe.score(X_test, y_test)\n",
    "\n",
    "R_2.mean()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
